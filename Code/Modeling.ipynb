{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Machine Learning Models\n",
    "Now we will train several Machine Learning models and compare their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('../data/train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the preprocessed dataset from util\n",
    "from ipynb.fs.full.utils import preprocess\n",
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>fam_size</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_3</th>\n",
       "      <th>Fare_4</th>\n",
       "      <th>Fare_5</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>fam_size_1</th>\n",
       "      <th>fam_size_2</th>\n",
       "      <th>fam_size_3</th>\n",
       "      <th>fam_size_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  \\\n",
       "PassengerId                                                             \n",
       "1                   0       3    1    1      1      0     0         2   \n",
       "2                   1       1    0    2      1      0     4         0   \n",
       "3                   1       3    0    1      0      0     0         2   \n",
       "4                   1       1    0    2      1      0     4         2   \n",
       "5                   0       3    1    2      0      0     1         2   \n",
       "\n",
       "             fam_size  Embarked_1  ...  Fare_3  Fare_4  Fare_5  Pclass_1  \\\n",
       "PassengerId                        ...                                     \n",
       "1                   2         0.0  ...     0.0     0.0     0.0       0.0   \n",
       "2                   2         1.0  ...     0.0     0.0     1.0       1.0   \n",
       "3                   1         0.0  ...     0.0     0.0     0.0       0.0   \n",
       "4                   2         0.0  ...     0.0     0.0     1.0       1.0   \n",
       "5                   1         0.0  ...     0.0     0.0     0.0       0.0   \n",
       "\n",
       "             Pclass_2  Pclass_3  fam_size_1  fam_size_2  fam_size_3  \\\n",
       "PassengerId                                                           \n",
       "1                 0.0       1.0         0.0         1.0         0.0   \n",
       "2                 0.0       0.0         0.0         1.0         0.0   \n",
       "3                 0.0       1.0         1.0         0.0         0.0   \n",
       "4                 0.0       0.0         0.0         1.0         0.0   \n",
       "5                 0.0       1.0         1.0         0.0         0.0   \n",
       "\n",
       "             fam_size_4  \n",
       "PassengerId              \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "      <th>Embarked_3</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Sex_2</th>\n",
       "      <th>Age_1</th>\n",
       "      <th>Age_2</th>\n",
       "      <th>Age_3</th>\n",
       "      <th>Age_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_3</th>\n",
       "      <th>Fare_4</th>\n",
       "      <th>Fare_5</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>fam_size_1</th>\n",
       "      <th>fam_size_2</th>\n",
       "      <th>fam_size_3</th>\n",
       "      <th>fam_size_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Embarked_1  Embarked_2  Embarked_3  Sex_1  Sex_2  \\\n",
       "PassengerId                                                               \n",
       "1                   0         0.0         0.0         1.0    0.0    1.0   \n",
       "2                   1         1.0         0.0         0.0    1.0    0.0   \n",
       "\n",
       "             Age_1  Age_2  Age_3  Age_4  ...  Fare_3  Fare_4  Fare_5  \\\n",
       "PassengerId                              ...                           \n",
       "1              0.0    1.0    0.0    0.0  ...     0.0     0.0     0.0   \n",
       "2              0.0    0.0    1.0    0.0  ...     0.0     0.0     1.0   \n",
       "\n",
       "             Pclass_1  Pclass_2  Pclass_3  fam_size_1  fam_size_2  fam_size_3  \\\n",
       "PassengerId                                                                     \n",
       "1                 0.0       0.0       1.0         0.0         1.0         0.0   \n",
       "2                 1.0       0.0       0.0         0.0         1.0         0.0   \n",
       "\n",
       "             fam_size_4  \n",
       "PassengerId              \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = df.drop(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'fam_size'], axis=1)\n",
    "dfm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset so that we can train the model with the training set and test the predictive power with the test dataset\n",
    "X = dfm.drop(\"Survived\", axis=1)\n",
    "y = dfm[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "#Normalize the training variables using Standard Scaling to bring all of them to the same level of magnitude.\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((223, 22), (668, 22), (223,), (668,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape, y_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pbamo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pbamo\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Train_Score  Test_Score\n",
      "Model                                              \n",
      "Decision Tree                     88.17       80.27\n",
      "Random Forest                     88.17       83.41\n",
      "KNN                               83.98       71.75\n",
      "Logistic Regression               83.23       81.17\n",
      "Support Vector Machines           82.34       82.06\n",
      "Perceptron                        77.54       78.48\n",
      "Stochastic Gradient Decent        76.65       72.65\n",
      "Naive Bayes                       76.35       76.23\n"
     ]
    }
   ],
   "source": [
    "#Create a function within many Machine Learning Models\n",
    "#source : https://medium.com/better-programming/titanic-survival-prediction-using-machine-learning-4c5ff1e3fa16\n",
    "\n",
    "def models(X_train,y_train):\n",
    "          \n",
    "#Logistic Regression\n",
    "    logreg = LogisticRegression(random_state =42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "#Decision Tree Classifier\n",
    "    tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "#Random Forest Classifier\n",
    "    RF = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "    RF.fit(X_train, y_train)\n",
    "    \n",
    "#Stochastic Gradient Descent (SGD)\n",
    "    sgd = linear_model.SGDClassifier(max_iter=5, random_state=42, tol=None)\n",
    "    sgd.fit(X_train, y_train)\n",
    "    \n",
    "#K Nearest Neighbor\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "#Gaussian Naive Bayes:\n",
    "    gaussian = GaussianNB() \n",
    "    gaussian.fit(X_train, y_train)\n",
    "    \n",
    "#Perceptron\n",
    "    perceptron = Perceptron(max_iter=5, random_state=42)\n",
    "    perceptron.fit(X_train, y_train)\n",
    "\n",
    "#Linear Support Vector Machine\n",
    "    linear_svc = LinearSVC(random_state=42)\n",
    "    linear_svc.fit(X_train, y_train)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Stochastic Gradient Decent', \n",
    "                'KNN', 'Naive Bayes', 'Perceptron', 'Support Vector Machines'],\n",
    "    'Train_Score': [round(logreg.score(X_train, y_train) * 100, 2), round(tree.score(X_train, y_train) * 100, 2), \n",
    "              round(RF.score(X_train, y_train) * 100, 2), round(sgd.score(X_train, y_train) * 100, 2),\n",
    "            round(knn.score(X_train, y_train) * 100, 2), round(gaussian.score(X_train, y_train) * 100, 2), \n",
    "            round(perceptron.score(X_train, y_train) * 100, 2), round(linear_svc.score(X_train, y_train) * 100, 2)],\n",
    "    'Test_Score': [round(logreg.score(X_test, y_test) * 100, 2), round(tree.score(X_test, y_test) * 100, 2), \n",
    "              round(RF.score(X_test, y_test) * 100, 2), round(sgd.score(X_test, y_test) * 100, 2),\n",
    "            round(knn.score(X_test, y_test) * 100, 2), round(gaussian.score(X_test, y_test) * 100, 2), \n",
    "            round(perceptron.score(X_test, y_test) * 100, 2), round(linear_svc.score(X_test, y_test) * 100, 2)]})\n",
    "            \n",
    "    result = results.sort_values(by='Train_Score', ascending=False)\n",
    "    result = result.set_index('Model')\n",
    "    print(result)\n",
    "    \n",
    "    return logreg, tree, RF, sgd, knn, gaussian, perceptron, linear_svc\n",
    "\n",
    "#Get and train all the models and store them in a variable called model.\n",
    "\n",
    "model = models(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, the decision tree and random forest classifier are tied at 88.17% training accuracy, but I am going to adjudge and proceed with the Random Forest Classifier as the best performer because of it higher accuracy on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  16]\n",
      " [ 26  63]]\n",
      "Model[0] Testing Accuracy = \"0.8116591928251121 !\"\n",
      "\n",
      "[[120  14]\n",
      " [ 30  59]]\n",
      "Model[1] Testing Accuracy = \"0.8026905829596412 !\"\n",
      "\n",
      "[[115  19]\n",
      " [ 18  71]]\n",
      "Model[2] Testing Accuracy = \"0.8340807174887892 !\"\n",
      "\n",
      "[[100  34]\n",
      " [ 27  62]]\n",
      "Model[3] Testing Accuracy = \"0.726457399103139 !\"\n",
      "\n",
      "[[90 44]\n",
      " [19 70]]\n",
      "Model[4] Testing Accuracy = \"0.7174887892376681 !\"\n",
      "\n",
      "[[106  28]\n",
      " [ 25  64]]\n",
      "Model[5] Testing Accuracy = \"0.7623318385650224 !\"\n",
      "\n",
      "[[107  27]\n",
      " [ 21  68]]\n",
      "Model[6] Testing Accuracy = \"0.7847533632286996 !\"\n",
      "\n",
      "[[120  14]\n",
      " [ 26  63]]\n",
      "Model[7] Testing Accuracy = \"0.820627802690583 !\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Further Evaluation: Confusion matrix and accuracy for all the models on the test data\n",
    "from sklearn.metrics import confusion_matrix \n",
    "for i in range(len(model)):\n",
    "    cm = confusion_matrix(y_test, model[i].predict(X_test)) \n",
    "    #extracting TN, FP, FN, TP\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, model[i].predict(X_test)).ravel()\n",
    "    print(cm)\n",
    "    print('Model[{}] Testing Accuracy = \"{} !\"'.format(i,  (TP + TN) / (TP + TN + FN + FP)))\n",
    "    print()# Print a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Survived', 'Embarked_1', 'Embarked_2', 'Embarked_3', 'Sex_1',\n",
       "       'Sex_2', 'Age_1', 'Age_2', 'Age_3', 'Age_4', 'Age_5', 'Fare_1',\n",
       "       'Fare_2', 'Fare_3', 'Fare_4', 'Fare_5', 'Pclass_1', 'Pclass_2',\n",
       "       'Pclass_3', 'fam_size_1', 'fam_size_2', 'fam_size_3', 'fam_size_4'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict your survival using the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh no! LogisticRegression(random_state=42) predicted that you will not make it\n",
      "Oh no! DecisionTreeClassifier(criterion='entropy', random_state=42) predicted that you will not make it\n",
      "Oh no! RandomForestClassifier(criterion='entropy', random_state=42) predicted that you will not make it\n",
      "Oh no! SGDClassifier(max_iter=5, random_state=42, tol=None) predicted that you will not make it\n",
      "Oh no! KNeighborsClassifier(n_neighbors=3) predicted that you will not make it\n",
      "Oh no! GaussianNB() predicted that you will not make it\n",
      "Oh no! Perceptron(max_iter=5, random_state=42) predicted that you will not make it\n",
      "Oh no! LinearSVC(random_state=42) predicted that you will not make it\n"
     ]
    }
   ],
   "source": [
    "your_data = [[1,0,0,0, 1, 0, 1, 1, 0, 0, 1,0,0,0,1, 1,0,0,1,0,0,0]]\n",
    "\n",
    "for i in range(len(model)):\n",
    "    test = model[i].predict(your_data)\n",
    "    if test == 0:\n",
    "      print('Oh no!', model[i], 'predicted that you will not make it')\n",
    "    else:\n",
    "      print('\\033[1m' + '\\033[94m' + 'Nice!', model[i], 'predicted that you will survive' + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the input data, none of the models predicted a survival, in some instances, the SGD Classifier did though, we are however going to proceed with the Random Forest classifier to see if we can improve the accuracy through tuning the hyperparameters, dropping some least important features, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 16,\n",
       " 'n_estimators': 700}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Find the best parameters for the model\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \"n_estimators\": [100, 400, 700, 1000, 1500]}\n",
    "\n",
    "#initiate model\n",
    "RF = RandomForestClassifier(n_estimators=100, max_features='auto', random_state=1, n_jobs=-1)\n",
    "grid_search = GridSearchCV(estimator=RF, param_grid=param_grid, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# best parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 85.18 %\n"
     ]
    }
   ],
   "source": [
    "#Retrain Random Forest with the new parameters\n",
    "Random_forest = RandomForestClassifier(criterion = \"gini\", \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       min_samples_split = 16,   \n",
    "                                       n_estimators=700)\n",
    "\n",
    "Random_forest.fit(X_train, y_train)\n",
    "y_pred = Random_forest.predict(X_test)\n",
    "\n",
    "accuracy = Random_forest.score(X_train, y_train)\n",
    "\n",
    "print(\"accuracy score:\", round(accuracy, 4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, after tuning the hyperparameters, we get a reduction in the accuracy by ca. 3%, so the next step generally will be to select more parameters for optimization, which normally takes a lot of time, or possibly try another optimization technique, like RandomizedSearchCV, but we will leave that for now and check further methods of evaluating the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[381,  34],\n",
       "       [ 80, 173]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Confusion Matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = cross_val_predict(Random_forest, X_train, y_train, cv=3)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True,fmt='.0f',cmap='jet')\n",
    "plt.savefig('../Images/Confusion Matrix Random Forest',dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, the true negatives was 381, which means 381 passengers were correctly predicted as did not survive while 34 false negatives were detected. On the 2nd row, 80 false positives were detected, while 173 true positives representing correct prediction of passengers who survived were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8357487922705314\n",
      "Recall: 0.6837944664031621\n"
     ]
    }
   ],
   "source": [
    "# ii. Precision and Recall\n",
    "print(\"Precision:\", precision_score(y_train, y_pred))\n",
    "print(\"Recall:\",recall_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **precision** tells us that our model predicts 73% of the time, a passenger's survival correctly while the **recall** tells us that it predicted the survival of 68% of the people who actually survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "We started with data exploration, cleaning, feature modification and creation and made predictions using 8 models from which we proceeded with the random forest classifier as the best based on the accuracy. We further proceeded to tune the hyperparameters of our chosen model after which we looked at some further methods of evaluating the model's performance. The results looked promising but of course there is still room for improvement, like doing a more extensive hyperparameter optimization on several models, identifying and removing less important features which create unnecessary noise that interferes with our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
